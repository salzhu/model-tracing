{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7b4fb2-484d-4931-8f95-bf08c215593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d136e502-55ae-49c6-a32b-4c4a8f5232bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_keys(d, n):\n",
    "    return random.sample(list(d.keys()), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92dcd5c9-53de-4504-a79b-d08f0e8dbfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a705e29-1dd4-45f3-8525-647be904ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Desktop/pile_pythia_pplx_10k_gptj.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45776940-393f-40d6-b664-cfb03df84061",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [500, 1000, 2000, 4000, 6000, 8000, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e93f00-b564-4830-8719-6641242aa388",
   "metadata": {},
   "source": [
    "### (diff model = reference model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ebc8e-cb12-4e9a-a3c9-f72aa29af1d2",
   "metadata": {},
   "source": [
    "### No difference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89058ec8-3c77-4ae5-b221-6513511e1c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: None\n",
      "\n",
      "500 0.451511393389349\n",
      "1000 0.3874607076005504\n",
      "2000 0.06312504195726486\n",
      "4000 0.30076504215961036\n",
      "6000 0.3069801899642444\n",
      "8000 0.3911058496219253\n",
      "10000 0.2133978224203535\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: None\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], -df_sample['deduped_pplx'])\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373904e9-34dd-494a-bcf7-54585c497c8c",
   "metadata": {},
   "source": [
    "### Pythia reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46af9e4-0049-4a4d-ace4-214e51860d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: pythia-duped-6.9b\n",
      "\n",
      "500 0.005392014801079363\n",
      "1000 5.315932405344063e-05\n",
      "2000 1.1782825573026501e-06\n",
      "4000 2.2045749702961732e-08\n",
      "6000 4.9725838938692856e-15\n",
      "8000 1.1310785621105327e-16\n",
      "10000 8.032984078932448e-20\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: pythia-duped-6.9b\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], df_sample['duped_pplx'] - df_sample['deduped_pplx'])\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b585ff7-35c8-46e7-be2d-927e6b63f73b",
   "metadata": {},
   "source": [
    "### Llama reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7afaafc-3d2e-4496-9021-58f67ff7cd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: llama3-8b\n",
      "\n",
      "500 0.5411376516805082\n",
      "1000 0.5680890303569781\n",
      "2000 0.19229275652388464\n",
      "4000 0.006086050290524001\n",
      "6000 0.1810272621766135\n",
      "8000 0.10800484843994829\n",
      "10000 0.00799426148457033\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: llama3-8b\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], df_sample['llama3_pplx'] - df_sample['deduped_pplx'])\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1270414-6856-477b-8ddf-19fe20f41dd0",
   "metadata": {},
   "source": [
    "### Reference model = averaging over Pythia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e4f76c5-2e61-4ff3-9cbc-cd382e894b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: avg. pythia\n",
      "\n",
      "500 0.07159199008440532\n",
      "1000 0.1262794757375701\n",
      "2000 0.004629676565855284\n",
      "4000 0.0014216568142167902\n",
      "6000 0.000545564973951944\n",
      "8000 3.209966957637225e-05\n",
      "10000 1.6743454961093683e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: avg. pythia\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    models = ['duped_pplx', 'deduped-1-4b', 'deduped-2-8b', 'deduped-1b', 'deduped-410m',\n",
    "       'deduped-160m', 'deduped-70m', 'duped-2-8b', 'duped-1-4b', 'duped-1b',\n",
    "       'duped-410m', 'duped-160m']\n",
    "    avg_pplx = np.zeros(len(df_sample))\n",
    "    for model in models:\n",
    "        avg_pplx += df_sample[model]\n",
    "    avg_pplx /= len(models)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], avg_pplx - df_sample['deduped_pplx'])\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77404f7-fbb1-4f82-8545-cf6b86d4f36a",
   "metadata": {},
   "source": [
    "### Reference model = averaging over Llama1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3bcf639-513e-4832-8125-3f8f4f0a87c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: avg. llama\n",
      "\n",
      "500 0.03506773970496128\n",
      "1000 0.5703938986145594\n",
      "2000 0.7355982395366336\n",
      "4000 0.09804675321784534\n",
      "6000 0.012049574098794738\n",
      "8000 0.0054571112453445005\n",
      "10000 0.003890886928543179\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: avg. llama\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    models = ['llama3_pplx', 'llama2-7b', 'llama1-7b']\n",
    "    avg_pplx = np.zeros(len(df_sample))\n",
    "    for model in models:\n",
    "        avg_pplx += df_sample[model]\n",
    "    avg_pplx /= len(models)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], avg_pplx - df_sample['deduped_pplx'])\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35745c0f-a4e7-41bd-a07b-7c233dbec9d4",
   "metadata": {},
   "source": [
    "## Doing some normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c51867cc-cb78-447a-8c89-aff2f29faaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: MINMAX NORM. pythia-duped-6.9b\n",
      "\n",
      "500 0.6516623332425857\n",
      "1000 0.005666515628304675\n",
      "2000 2.25158539921238e-05\n",
      "4000 4.229314217788246e-08\n",
      "6000 1.3056100102241288e-13\n",
      "8000 2.4525927921180357e-15\n",
      "10000 4.0800380274280514e-20\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: MINMAX NORM. pythia-duped-6.9b\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], \n",
    "                                       (df_sample['duped_pplx'] - min(df_sample['duped_pplx'])) / (max(df_sample['duped_pplx']) - min(df_sample['duped_pplx'])) - \n",
    "                                       (df_sample['deduped_pplx'] - min(df_sample['deduped_pplx'])) / (max(df_sample['deduped_pplx']) - min(df_sample['deduped_pplx'])))\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b827bff4-00d8-4f0e-821c-8b1766c0a7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: STD NORM. pythia-duped-6.9b\n",
      "\n",
      "500 0.2520034402104735\n",
      "1000 0.027821891194410947\n",
      "2000 0.00039541351922579897\n",
      "4000 1.172019128514986e-07\n",
      "6000 1.4572920302581844e-09\n",
      "8000 3.4935378284883042e-15\n",
      "10000 4.059541583049317e-20\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: STD NORM. pythia-duped-6.9b\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], \n",
    "                                       (df_sample['duped_pplx'] - np.mean(df_sample['duped_pplx'])) / np.std(df_sample['duped_pplx'])- \n",
    "                                       (df_sample['deduped_pplx'] - np.mean(df_sample['deduped_pplx'])) / np.std(df_sample['deduped_pplx']))\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e708a-d29a-4533-89c1-8b9b362bae2b",
   "metadata": {},
   "source": [
    "### Using each of the Pythia duped models as a reference model for Pythia 6.9b-deduped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab1b51-2c0c-4764-a965-993d5a31023e",
   "metadata": {},
   "source": [
    "Generally, model closer in size (bigger model) works better as a reference model (lower PPLX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b168e33e-0aaa-426f-a930-1518cdebd5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "duped_pplx 500 0.5232468044954425\n",
      "duped-2-8b 500 0.29372762611451136\n",
      "duped-1-4b 500 0.7711060895901847\n",
      "duped-1b 500 0.9262985060646471\n",
      "duped-410m 500 0.9118970176249057\n",
      "duped-160m 500 0.7685407624684397\n",
      "\n",
      "1000\n",
      "duped_pplx 1000 0.0003905897577136928\n",
      "duped-2-8b 1000 0.06207427760500445\n",
      "duped-1-4b 1000 0.02565852271844251\n",
      "duped-1b 1000 0.17669874878617467\n",
      "duped-410m 1000 0.10368078363962951\n",
      "duped-160m 1000 0.07907387609174789\n",
      "\n",
      "2000\n",
      "duped_pplx 2000 2.593331417877856e-05\n",
      "duped-2-8b 2000 0.0036556239218365223\n",
      "duped-1-4b 2000 0.013233330200129257\n",
      "duped-1b 2000 0.05504848402969311\n",
      "duped-410m 2000 0.2274933097081205\n",
      "duped-160m 2000 0.9028021481207623\n",
      "\n",
      "4000\n",
      "duped_pplx 4000 4.94413941758504e-07\n",
      "duped-2-8b 4000 4.089779303004275e-05\n",
      "duped-1-4b 4000 1.902322320728162e-05\n",
      "duped-1b 4000 0.00016959852595525737\n",
      "duped-410m 4000 0.002344975529700958\n",
      "duped-160m 4000 0.004061809555769445\n",
      "\n",
      "6000\n",
      "duped_pplx 6000 3.057592390281609e-15\n",
      "duped-2-8b 6000 6.983731723026605e-12\n",
      "duped-1-4b 6000 3.3823843471547657e-09\n",
      "duped-1b 6000 6.38215882704187e-07\n",
      "duped-410m 6000 0.00020793539634057995\n",
      "duped-160m 6000 0.011720245901486124\n",
      "\n",
      "8000\n",
      "duped_pplx 8000 4.535157646928405e-15\n",
      "duped-2-8b 8000 2.031280654728283e-12\n",
      "duped-1-4b 8000 1.043667179867431e-09\n",
      "duped-1b 8000 4.688592686213033e-09\n",
      "duped-410m 8000 1.616424693830831e-05\n",
      "duped-160m 8000 0.0008403940623091115\n",
      "\n",
      "10000\n",
      "duped_pplx 10000 8.032984078932448e-20\n",
      "duped-2-8b 10000 1.0021024722441835e-15\n",
      "duped-1-4b 10000 8.131227940590134e-12\n",
      "duped-1b 10000 7.318053867437338e-10\n",
      "duped-410m 10000 2.5309147856694596e-06\n",
      "duped-160m 10000 0.0011728004494944695\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    print(num)\n",
    "    models = ['duped_pplx', 'duped-2-8b', 'duped-1-4b', 'duped-1b',\n",
    "       'duped-410m', 'duped-160m']\n",
    "    for diff_model in models:\n",
    "        print(diff_model, end = ' ')\n",
    "        cor, pvalue = scipy.stats.spearmanr(df_sample['index'], df_sample[diff_model] - df_sample['deduped_pplx'])\n",
    "        print(num, pvalue)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c039091-6fc1-4bff-813a-c45c7e0eb219",
   "metadata": {},
   "source": [
    "Llama2-7B is a bad reference model (relatively high p-values). We suspect it's because it's trained on different\n",
    "data than the Pythia models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "537cf7a8-da16-484a-9daf-6963544e7a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: llama2-7b\n",
      "\n",
      "500 0.26861665675303514\n",
      "1000 0.68693507015899\n",
      "2000 0.34164976949410464\n",
      "4000 0.011173478917135164\n",
      "6000 0.0001366073886289737\n",
      "8000 0.0074291704239786\n",
      "10000 0.004949236011227232\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: llama2-7b\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], df_sample['llama2-7b'] - df_sample['deduped_pplx'])\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667825c-85c7-4253-9c99-1be5bbc706e1",
   "metadata": {},
   "source": [
    "***GPT-J test***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4554d5-34e0-4be2-a247-8eea63cdb94d",
   "metadata": {},
   "source": [
    "GPT-J had more overlap in training data with Pythia, so might be a better reference model?\n",
    "(It is; lower p-values compared to Llama2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1347383f-76d9-4c0a-b016-38e27f5cc4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diff model: gpt-j-6b\n",
      "\n",
      "500 0.4752496323220523\n",
      "1000 0.10094909640464075\n",
      "2000 0.02274583892932036\n",
      "4000 0.03518705957845987\n",
      "6000 0.0006934982882806516\n",
      "8000 0.008349819023537304\n",
      "10000 0.0003368746002582249\n"
     ]
    }
   ],
   "source": [
    "print(\"Diff model: gpt-j-6b\")\n",
    "print()\n",
    "\n",
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    cor, pvalue = scipy.stats.spearmanr(df_sample['index'], df_sample['gpt-j-6b'] - df_sample['deduped_pplx'])\n",
    "    print(num, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75af000-8166-4c9a-a5f7-85ebe8cd4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "gpt-j-6b 500 0.3445534792502537\n",
      "llama2-7b 500 0.0031335462568181315\n",
      "\n",
      "1000\n",
      "gpt-j-6b 1000 0.049156271541169916\n",
      "llama2-7b 1000 0.8665978009582441\n",
      "\n",
      "2000\n",
      "gpt-j-6b 2000 0.02440365309855038\n",
      "llama2-7b 2000 0.5017829857970226\n",
      "\n",
      "4000\n",
      "gpt-j-6b 4000 0.009189705205548413\n",
      "llama2-7b 4000 0.020352292810525932\n",
      "\n",
      "6000\n",
      "gpt-j-6b 6000 0.0003929187083492641\n",
      "llama2-7b 6000 0.012210158488851453\n",
      "\n",
      "8000\n",
      "gpt-j-6b 8000 0.0023884058138882547\n",
      "llama2-7b 8000 0.003558697446652442\n",
      "\n",
      "10000\n",
      "gpt-j-6b 10000 0.0003368746002582249\n",
      "llama2-7b 10000 0.004949236011227232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num in sample_sizes:\n",
    "    df_sample = df.sample(n=num)\n",
    "    print(num)\n",
    "    models = ['gpt-j-6b', 'llama2-7b']\n",
    "    for diff_model in models:\n",
    "        print(diff_model, end = ' ')\n",
    "        cor, pvalue = scipy.stats.spearmanr(df_sample['index'], df_sample[diff_model] - df_sample['deduped_pplx'])\n",
    "        print(num, pvalue)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde9208a-4d1d-4df6-80fc-9fd815cbc52c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
