Model Pair,jsd_wikitext_batch, jsd_test_input
meta-llama/Llama-2-7b-hf vs codellama/CodeLlama-7b-hf,1.9561830413294956e-06,3.245754214731278e-06
meta-llama/Llama-2-7b-hf vs openlm-research/open_llama_7b,1.729454925225582e-05,2.0375082385726273e-05
meta-llama/Llama-2-7b-hf vs huggyllama/llama-7b,2.1560920231422642e-06,1.0297326298314147e-06
meta-llama/Llama-2-7b-hf vs lmsys/vicuna-7b-v1.5,1.5276991689461283e-06,4.193487256998196e-06
meta-llama/Llama-2-7b-hf vs EleutherAI/llemma_7b,2.434112047922099e-06,4.357912075647619e-06
meta-llama/Llama-2-7b-hf vs lmsys/vicuna-7b-v1.1,3.127033551209024e-06,3.4884374144894537e-06
meta-llama/Llama-2-7b-hf vs microsoft/Orca-2-7b,2.6865156996791484e-06,4.245463969709817e-06
meta-llama/Llama-2-7b-hf vs LLM360/Amber,1.8514610928832553e-06,3.480401119304588e-06
codellama/CodeLlama-7b-hf vs openlm-research/open_llama_7b,1.7027690773829818e-05,1.983477886824403e-05
codellama/CodeLlama-7b-hf vs huggyllama/llama-7b,2.795685531964409e-06,3.3317055567749776e-06
codellama/CodeLlama-7b-hf vs lmsys/vicuna-7b-v1.5,3.2359234864998143e-06,4.885899215878453e-06
codellama/CodeLlama-7b-hf vs EleutherAI/llemma_7b,1.8831561874321778e-06,4.028150215162896e-06
codellama/CodeLlama-7b-hf vs lmsys/vicuna-7b-v1.1,3.955687134293839e-06,4.28245175498887e-06
codellama/CodeLlama-7b-hf vs microsoft/Orca-2-7b,3.917118647223106e-06,5.343406428437447e-06
codellama/CodeLlama-7b-hf vs LLM360/Amber,2.043052063527284e-06,3.20175354318053e-06
openlm-research/open_llama_7b vs huggyllama/llama-7b,1.7465732526034117e-05,2.0448682334972546e-05
openlm-research/open_llama_7b vs lmsys/vicuna-7b-v1.5,1.7609712813282385e-05,2.049213435384445e-05
openlm-research/open_llama_7b vs EleutherAI/llemma_7b,1.706841794657521e-05,2.0151202988927253e-05
openlm-research/open_llama_7b vs lmsys/vicuna-7b-v1.1,1.7788930563256145e-05,2.0416322513483465e-05
openlm-research/open_llama_7b vs microsoft/Orca-2-7b,1.767633148119785e-05,2.018710074480623e-05
openlm-research/open_llama_7b vs LLM360/Amber,1.7064834537450224e-05,2.0156170648988336e-05
huggyllama/llama-7b vs lmsys/vicuna-7b-v1.5,3.4697009141382296e-06,4.354528755357023e-06
huggyllama/llama-7b vs EleutherAI/llemma_7b,3.1778936318005435e-06,4.261534741090145e-06
huggyllama/llama-7b vs lmsys/vicuna-7b-v1.1,1.5405695421577548e-06,2.4467876755807083e-06
huggyllama/llama-7b vs microsoft/Orca-2-7b,4.071262083016336e-06,4.621022526407614e-06
huggyllama/llama-7b vs LLM360/Amber,2.3568713913846295e-06,3.4077993404935114e-06
lmsys/vicuna-7b-v1.5 vs EleutherAI/llemma_7b,3.499165813991567e-06,5.325471647665836e-06
lmsys/vicuna-7b-v1.5 vs lmsys/vicuna-7b-v1.1,3.2389764328399906e-06,3.7683282698708354e-06
lmsys/vicuna-7b-v1.5 vs microsoft/Orca-2-7b,2.189671249652747e-06,3.5288214803586015e-06
lmsys/vicuna-7b-v1.5 vs LLM360/Amber,2.9944339985377155e-06,4.550915946310852e-06
EleutherAI/llemma_7b vs lmsys/vicuna-7b-v1.1,4.045330570079386e-06,5.489064733410487e-06
EleutherAI/llemma_7b vs microsoft/Orca-2-7b,3.952619408664759e-06,6.314553502306808e-06
EleutherAI/llemma_7b vs LLM360/Amber,2.333970769541338e-06,3.391487553017214e-06
lmsys/vicuna-7b-v1.1 vs microsoft/Orca-2-7b,3.713232445079484e-06,4.426544364832807e-06
lmsys/vicuna-7b-v1.1 vs LLM360/Amber,3.438890416873619e-06,4.203274784231326e-06
microsoft/Orca-2-7b vs LLM360/Amber,3.5631983337225392e-06,5.076844900031574e-06